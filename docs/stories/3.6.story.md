# Story 3.6: Node Submission to OpenAI API Integration

## Status
Done

## Story

**As a** user,
**I want** my submitted message to trigger an actual OpenAI API call,
**so that** I receive a real LLM response instead of just a loading state.

## Acceptance Criteria

1. When a user submits a message, the system calls the `/api/chat` endpoint
2. The system passes the active node path as context to the API
3. The API processes the request and returns an LLM response
4. The node transitions from loading to completed state with the response
5. Error handling is implemented for failed API calls
6. The conversation state is properly updated with the response
7. Context flattening is integrated with the API call

## Tasks / Subtasks

- [x] Task 1: Implement Frontend API Integration (AC: 1, 4, 6)
  - [x] Create API client service for chat requests
  - [x] Update ConversationPage to call chat API on message submission
  - [x] Implement proper error handling for API failures
  - [x] Add loading state management during API calls
  - [x] Update conversation state with API response

- [x] Task 2: Integrate Context Flattening (AC: 2, 7)
  - [x] Implement active node path calculation
  - [x] Create context flattening service
  - [x] Pass flattened context to chat API
  - [x] Handle context length management
  - [x] Add context validation before API calls

- [x] Task 3: Update Node State Management (AC: 4, 6)
  - [x] Modify node state transitions (loading → completed)
  - [x] Update ConversationNode to handle API responses
  - [x] Implement proper state updates after API success
  - [x] Add error state handling for failed API calls
  - [x] Ensure state consistency across components

- [x] Task 4: Implement Error Handling (AC: 5)
  - [x] Add error handling for API failures
  - [x] Implement retry logic for transient errors
  - [x] Add user feedback for error states
  - [x] Handle network timeouts and connection issues
  - [x] Implement graceful degradation

- [x] Task 5: Add Response Processing (AC: 4, 6)
  - [x] Process OpenAI API response format
  - [x] Update node with assistant response
  - [x] Handle markdown content in responses
  - [x] Implement response validation
  - [x] Add response metadata handling

- [x] Task 6: Create Unit Tests (AC: 1-7)
  - [x] Test API integration functionality
  - [x] Test context flattening integration
  - [x] Test node state transitions
  - [x] Test error handling scenarios
  - [x] Test response processing

## Dev Notes

### Previous Story Insights
**Story 3.1 Context** [Source: stories/3.1.story.md]
- OpenAI API integration is implemented
- Chat API route exists at `/api/chat`
- Basic request/response data models are defined
- Error handling and monitoring are in place

**Story 3.2 Context** [Source: stories/3.2.story.md]
- Context flattening and path traversal are implemented
- ContextService handles conversation path processing
- Path calculation and context management are working
- Chat API integration with context is complete

**Story 2.3 Context** [Source: stories/2.3.story.md]
- Node state management and loading states are implemented
- ConversationNode component handles different states
- NodeLoading component exists for loading state display
- State transitions from input → loading → completed are planned

### Data Models
**ChatRequest Interface** [Source: types/index.ts]
```typescript
interface ChatRequest {
  message: string;
  context: ChatMessage[];
  nodeId: string;
  conversationId: string;
}
```

**ChatResponse Interface** [Source: types/index.ts]
```typescript
interface ChatResponse {
  content: string;
  nodeId: string;
  conversationId: string;
  timestamp: Date;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}
```

**ContextMessage Interface** [Source: types/index.ts]
```typescript
interface ContextMessage {
  role: 'user' | 'assistant';
  content: string;
  nodeId: string;
  timestamp: Date;
}
```

### API Specifications
**Chat API Endpoint** [Source: architecture/api-specification.md#chat-endpoint]
- Route: `POST /api/chat`
- Request body: ChatRequest with message, context, and nodeId
- Response: ChatResponse with LLM content
- Authentication: Session-based (NextAuth.js)
- Error handling: Standard HTTP status codes

**Request Format** [Source: architecture/api-specification.md#chat-endpoint]
```typescript
{
  "message": "string",
  "context": [
    {
      "role": "user" | "assistant",
      "content": "string"
    }
  ],
  "nodeId": "string",
  "conversationId": "string"
}
```

### Component Specifications
**ConversationPage Integration** [Source: architecture/frontend-architecture.md#component-organization]
- Location: `src/components/pages/ConversationPage.tsx`
- Functions: `handleMessageSubmit`, `processApiResponse`, `handleApiError`
- Manages API calls and state updates
- Handles error states and user feedback

**ConversationNode Updates** [Source: architecture/frontend-architecture.md#component-organization]
- Location: `src/components/graph/ConversationNode.tsx`
- Props: `onMessageSubmit`, `isLoading`, `error`
- Handles API response states
- Manages node state transitions

**ApiClient Service** [Source: architecture/backend-architecture.md#service-architecture]
- Location: `src/services/apiClient.ts`
- Functions: `sendChatRequest`, `handleApiError`, `processResponse`
- Manages API communication
- Handles request/response processing

### File Locations
**API Route Files** [Source: architecture/backend-architecture.md#function-organization]
- Chat API route: `src/app/api/chat/route.ts`
- Health check: `src/app/api/health/route.ts`

**Service Files** [Source: architecture/backend-architecture.md#service-architecture]
- Chat service: `src/services/chatService.ts`
- API client: `src/services/apiClient.ts`
- Context service: `src/services/contextService.ts`

**Component Files** [Source: architecture/unified-project-structure.md]
- ConversationPage: `src/components/pages/ConversationPage.tsx`
- ConversationNode: `src/components/graph/ConversationNode.tsx`
- NodeLoading: `src/components/graph/NodeLoading.tsx`

### Frontend API Integration
**API Client Implementation** [Source: architecture/frontend-architecture.md#state-management-patterns]
- Use fetch API for HTTP requests
- Handle request/response transformation
- Implement proper error handling
- Add request timeout handling

**State Management** [Source: architecture/frontend-architecture.md#state-management-patterns]
- Update conversation state with API responses
- Manage loading states during API calls
- Handle error states and user feedback
- Implement optimistic updates with rollback

### Context Integration
**Context Flattening** [Source: architecture/backend-architecture.md#service-architecture]
- Calculate active node path from clicked node
- Flatten path into user/assistant message pairs
- Format context for OpenAI API
- Handle context length management

**Path Calculation** [Source: architecture/frontend-architecture.md#state-management-patterns]
- Traverse graph from active node to root
- Handle complex branching scenarios
- Validate path integrity
- Optimize for performance

### Node State Management
**State Transitions** [Source: architecture/frontend-architecture.md#state-management-patterns]
- Input state: User can type and submit message
- Loading state: Message submitted, API call in progress
- Completed state: API response received, node complete
- Error state: API call failed, show error message

**State Updates** [Source: architecture/frontend-architecture.md#state-management-patterns]
- Update node with user message
- Set loading state during API call
- Update with assistant response on success
- Handle error states on failure

### Error Handling
**API Error Handling** [Source: architecture/error-handling-strategy.md#frontend-error-handling]
- Network error handling
- API error response handling
- Timeout error handling
- User feedback for errors

**Error Recovery** [Source: architecture/error-handling-strategy.md#frontend-error-handling]
- Retry logic for transient errors
- Fallback to error state
- User notification of errors
- Graceful degradation

### Response Processing
**Response Handling** [Source: architecture/backend-architecture.md#service-architecture]
- Parse OpenAI API response
- Extract content and metadata
- Validate response format
- Handle response errors

**Content Processing** [Source: architecture/frontend-architecture.md#component-organization]
- Process markdown content
- Handle code blocks and formatting
- Update node with response
- Maintain proper styling

### Performance Considerations
**API Optimization** [Source: architecture/security-and-performance.md#performance-optimization]
- Efficient request/response handling
- Proper timeout configuration
- Memory usage optimization
- Connection pooling

**State Management** [Source: architecture/security-and-performance.md#performance-optimization]
- Efficient state updates
- Minimal re-renders
- Proper cleanup
- Optimistic updates

### Testing Requirements
**Test File Locations** [Source: architecture/testing-strategy.md#frontend-tests]
- API integration tests: `tests/services/apiClient.test.ts`
- Component tests: `tests/components/pages/ConversationPage.test.tsx`
- Integration tests: `tests/integration/chat-flow.test.ts`

**Test Standards** [Source: architecture/testing-strategy.md#frontend-component-test]
- Use Jest + React Testing Library
- Mock API calls for testing
- Test error handling scenarios
- Test state transitions and updates

### Technical Constraints
**API Integration** [Source: architecture/tech-stack.md]
- Next.js API routes for backend
- Fetch API for frontend requests
- Proper error handling and timeouts
- Request/response validation

**State Management** [Source: architecture/frontend-architecture.md#state-management-patterns]
- React Context for global state
- Local state for component state
- Proper state validation
- Error boundary implementation

**Performance** [Source: architecture/security-and-performance.md#performance-optimization]
- Efficient API calls
- Proper loading states
- Memory usage optimization
- Smooth user experience

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-19 | 1.0 | Initial story creation | Scrum Master |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4 (Dev Agent)

### Debug Log References
- All tests passing with 48/48 test cases successful
- No linter errors detected
- Integration tests cover full chat flow from message submission to response

### Completion Notes List
- Successfully implemented frontend API integration with proper error handling
- Created comprehensive context service for path traversal and context flattening
- Updated ConversationPage to handle complete chat flow with loading states
- Implemented robust error handling with user feedback
- Added comprehensive unit tests covering all functionality
- All acceptance criteria met and tested

### File List
**New Files Created:**
- `src/services/contextService.ts` - Context flattening and path traversal service
- `tests/services/contextService.test.ts` - Context service unit tests
- `tests/services/apiClient.test.ts` - API client unit tests  
- `tests/components/pages/ConversationPage.test.tsx` - ConversationPage component tests
- `tests/integration/chat-flow.test.ts` - End-to-end chat flow integration tests

**Modified Files:**
- `src/services/apiClient.ts` - Added chat request methods and error handling
- `src/components/pages/ConversationPage.tsx` - Integrated chat API with context flattening

## QA Results
*To be populated by QA Agent*
