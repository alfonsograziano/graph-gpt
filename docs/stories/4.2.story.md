# Story 4.2: Contextual Message Preprocessing

## Status
Draft

## Story
**As a** developer,
**I want** to prepend contextual information to messages from markdown anchors,
**so that** the LLM understands the relationship between nodes.

## Acceptance Criteria

1. Messages from markdown anchors include "this message is related to ${node content}" prefix
2. Context extraction correctly identifies relevant content from parent node
3. Context preprocessing maintains message clarity and meaning
4. Context length is managed to stay within API limits
5. Context preprocessing works with various markdown content types
6. Context is properly formatted for LLM consumption
7. Context preprocessing doesn't interfere with normal message flow

## Tasks / Subtasks

- [ ] Task 1: Implement context extraction system (AC: 2, 5)
  - [ ] Create context extraction utility functions
  - [ ] Implement markdown content parsing for context identification
  - [ ] Add support for different markdown element types
  - [ ] Create context snippet generation logic

- [ ] Task 2: Implement message preprocessing pipeline (AC: 1, 3, 6)
  - [ ] Create message preprocessing service
  - [ ] Implement context prefix formatting
  - [ ] Add message clarity preservation logic
  - [ ] Integrate with existing chat service

- [ ] Task 3: Add context length management (AC: 4)
  - [ ] Implement context length validation
  - [ ] Add intelligent context truncation
  - [ ] Create API limit compliance checks
  - [ ] Add context prioritization logic

- [ ] Task 4: Integrate with LLM service (AC: 6, 7)
  - [ ] Update chat service to use context preprocessing
  - [ ] Ensure normal message flow remains unaffected
  - [ ] Add context-aware message formatting
  - [ ] Implement proper error handling for context issues

- [ ] Task 5: Testing and validation (AC: 1-7)
  - [ ] Write unit tests for context extraction utilities
  - [ ] Add integration tests for message preprocessing
  - [ ] Create E2E tests for context-aware conversations
  - [ ] Test context length management edge cases

## Dev Notes

### Previous Story Insights
- Story 4.1 establishes markdown anchor system and edge metadata structure
- Edge metadata includes `contextSnippet` field for storing extracted context
- Markdown element identification system is available for context extraction

### Data Models
[Source: architecture/data-models.md#edge]
- Edge model includes `EdgeMetadata.contextSnippet` for storing extracted context
- Edge type 'markdown' indicates context-aware connections
- Node model provides `assistantResponse` field containing markdown content for context extraction

### API Specifications
[Source: architecture/api-specification.md]
- Chat API should be extended to handle context preprocessing
- Context information should be included in message payload
- API should validate context length and format before LLM processing

### Component Specifications
[Source: architecture/frontend-architecture.md#frontend-services-layer]
- Context preprocessing should be implemented in service layer
- New service: `src/services/contextService.ts`
- Integration with existing `chatService.ts` for LLM communication
- Service should follow established API client patterns

### File Locations
[Source: architecture/unified-project-structure.md]
- New service: `src/services/contextService.ts`
- Update existing: `src/services/chatService.ts`
- New utilities: `src/utils/contextUtils.ts`
- Update types: `src/types/context.ts` (if needed)
- API route: `src/app/api/chat/route.ts` (update for context handling)

### Testing Requirements
[Source: architecture/testing-strategy.md#backend-tests]
- Unit tests: `tests/services/contextService.test.ts`
- Integration tests: `tests/api/chat.test.ts`
- E2E tests: `tests/e2e/context-preprocessing.spec.ts`
- Test file location follows `tests/services/` and `tests/api/` structure
- Use Jest + Supertest for API testing
- Use Playwright for E2E tests

### Technical Constraints
[Source: architecture/coding-standards.md]
- All API calls must go through service layer
- Context preprocessing must not interfere with normal message flow
- Error handling through standard error handler
- Type sharing through `src/types/` directory
- LLM integration must use chat service for OpenAI API calls

## Testing

### Testing Standards
[Source: architecture/testing-strategy.md]
- **Test file location**: `tests/services/` for service tests, `tests/api/` for API tests, `tests/e2e/` for E2E tests
- **Testing frameworks**: Jest + Supertest for backend tests, Playwright for E2E tests
- **Test patterns**: Follow established service test patterns with proper mocking
- **E2E requirements**: Test complete context preprocessing flow from anchor click to LLM response
- **Coverage requirements**: All context preprocessing functionality must be covered by tests

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2024-01-XX | 1.0 | Initial story creation | Scrum Master |

## Dev Agent Record

### Agent Model Used
_To be populated by development agent_

### Debug Log References
_To be populated by development agent_

### Completion Notes List
_To be populated by development agent_

### File List
_To be populated by development agent_

## QA Results
_To be populated by QA agent_
