# Story 3.1: OpenAI API Integration

## Status
Done

## Story

**As a** developer,
**I want** to integrate OpenAI API with the Next.js backend,
**so that** I can send user messages and receive LLM responses.

## Acceptance Criteria

1. OpenAI API is properly configured with environment variables
2. API route is created for handling LLM requests (/api/chat)
3. Request includes proper authentication and error handling
4. API accepts conversation context and user message
5. Response handling includes proper error cases and timeouts
6. API follows Next.js best practices for route handlers

## Tasks / Subtasks

- [x] Task 1: Environment Configuration Setup (AC: 1)
  - [x] Create environment variable configuration for OpenAI API key
  - [x] Add OpenAI API key validation in startup
  - [x] Configure API base URL and model settings
  - [x] Add environment variable documentation
  - [x] Create configuration service for API settings

- [x] Task 2: Create Chat API Route (AC: 2, 6)
  - [x] Create `/api/chat/route.ts` with POST handler
  - [x] Implement Next.js API route best practices
  - [x] Add proper TypeScript types for request/response
  - [x] Implement request validation and sanitization
  - [x] Add proper HTTP status codes and error responses

- [x] Task 3: OpenAI API Integration Service (AC: 3, 4, 5)
  - [x] Create ChatService for OpenAI API calls
  - [x] Implement authentication with API key
  - [x] Add conversation context handling
  - [x] Implement proper error handling and timeouts
  - [x] Add request/response logging for debugging

- [x] Task 4: Request/Response Data Models (AC: 4)
  - [x] Define ChatRequest interface for API input
  - [x] Define ChatResponse interface for API output
  - [x] Create context message format for OpenAI API
  - [x] Add validation schemas for request data
  - [x] Implement response transformation utilities

- [x] Task 6: Create Unit Tests (AC: 1-7)
  - [x] Test environment configuration loading
  - [x] Test API route handlers and validation
  - [x] Test OpenAI API integration service
  - [x] Test error handling and edge cases
  - [x] Test rate limiting and monitoring

## Dev Notes

### Previous Story Insights
**Epic 2 Context** [Source: stories/2.1-2.5.story.md]
- React Flow canvas is integrated and configured
- ConversationNode components handle different states (input, loading, completed)
- Graph state management is implemented with Context API
- Node activation and path calculation functionality exists
- Basic conversation structure and data models are established

### Data Models
**ChatRequest Interface** [Source: architecture/api-specification.md#chat-endpoint]
```typescript
interface ChatRequest {
  message: string;
  context: ChatMessage[];
  nodeId: string;
  conversationId: string;
}

interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
}
```

**ChatResponse Interface** [Source: architecture/api-specification.md#chat-endpoint]
```typescript
interface ChatResponse {
  content: string;
  nodeId: string;
  conversationId: string;
  timestamp: Date;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}
```

**OpenAI API Configuration** [Source: architecture/external-apis.md#openai-api]
- Base URL: `https://api.openai.com/v1`
- Authentication: Bearer token (API key)
- Endpoint: `POST /chat/completions`
- Rate limits based on usage tier and model

### API Specifications
**Chat API Endpoint** [Source: architecture/api-specification.md#chat-endpoint]
- Route: `POST /api/chat`
- Request body: ChatRequest with message, context, and nodeId
- Response: Streaming text/event-stream or JSON response
- Authentication: Session-based (NextAuth.js)
- Error handling: Standard HTTP status codes

**Request Format** [Source: architecture/api-specification.md#chat-endpoint]
```typescript
{
  "message": "string",
  "context": [
    {
      "role": "user" | "assistant",
      "content": "string"
    }
  ],
  "nodeId": "string"
}
```

### File Locations
**API Route Files** [Source: architecture/backend-architecture.md#function-organization]
- Chat API route: `src/app/api/chat/route.ts`
- Health check: `src/app/api/health/route.ts`
- Conversations API: `src/app/api/conversations/route.ts`

**Service Files** [Source: architecture/backend-architecture.md#service-architecture]
- Chat service: `src/services/chatService.ts`
- Configuration service: `src/services/configService.ts`
- Error handler: `src/utils/errorHandler.ts`

**Type Definitions** [Source: architecture/coding-standards.md#type-sharing]
- Shared types: `src/types/index.ts`
- API types: `src/types/api.ts`
- Chat types: `src/types/chat.ts`

### Backend Architecture
**Service Layer Pattern** [Source: architecture/backend-architecture.md#service-architecture]
- ChatService handles OpenAI API integration
- Repository pattern for data access
- Service functions follow template pattern
- Proper error handling and logging

**API Route Template** [Source: architecture/backend-architecture.md#function-template]
```typescript
import { NextRequest, NextResponse } from 'next/server';
import { ChatService } from '@/services/chatService';

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const response = await ChatService.sendMessage(body);
    return NextResponse.json(response);
  } catch (error) {
    return NextResponse.json(
      { error: 'Failed to process chat request' },
      { status: 500 }
    );
  }
}
```

### Environment Configuration
**Required Environment Variables** [Source: architecture/development-workflow.md#environment-configuration]
- `OPENAI_API_KEY`: OpenAI API authentication key
- `OPENAI_MODEL`: Model to use (e.g., 'gpt-4', 'gpt-3.5-turbo')
- `OPENAI_MAX_TOKENS`: Maximum tokens per request
- `OPENAI_TEMPERATURE`: Response creativity setting

**Configuration Service** [Source: architecture/backend-architecture.md#service-architecture]
- Centralized configuration management
- Environment variable validation
- Default value handling
- Type-safe configuration access

### Error Handling
**Error Response Format** [Source: architecture/error-handling-strategy.md#error-response-format]
```typescript
interface ErrorResponse {
  error: string;
  code?: string;
  details?: any;
  timestamp: string;
}
```

**Error Types** [Source: architecture/error-handling-strategy.md#backend-error-handling]
- API authentication errors (401)
- Rate limiting errors (429)
- OpenAI API errors (500+)
- Request validation errors (400)
- Timeout errors (408)

### Testing Requirements
**Test File Locations** [Source: architecture/testing-strategy.md#backend-tests]
- API tests: `tests/api/chat.test.ts`
- Service tests: `tests/services/chatService.test.ts`
- Integration tests: `tests/integration/openai.test.ts`

**Test Standards** [Source: architecture/testing-strategy.md#backend-api-test]
- Use Jest + Supertest for API testing
- Mock OpenAI API responses for unit tests
- Test error handling and edge cases
- Test authentication and authorization
- Test rate limiting and monitoring

### Technical Constraints
**OpenAI API Limits** [Source: architecture/external-apis.md#openai-api]
- Rate limits based on usage tier
- Token limits per request
- Request timeout handling
- Proper error response handling

**Next.js API Routes** [Source: architecture/tech-stack.md]
- Serverless function limitations
- Request/response size limits
- Timeout constraints
- Memory usage optimization

**Security Requirements** [Source: architecture/security-and-performance.md#security-requirements]
- API key protection and rotation
- Request validation and sanitization
- Rate limiting and abuse prevention
- Proper error message handling

### Performance Considerations
**API Optimization** [Source: architecture/security-and-performance.md#performance-optimization]
- Efficient request/response handling
- Proper timeout configuration
- Memory usage optimization
- Connection pooling for external APIs

**Monitoring and Logging** [Source: architecture/monitoring-and-observability.md]
- Request/response logging
- Error tracking and alerting
- Performance metrics collection
- Usage monitoring and analytics

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-19 | 1.0 | Initial story creation | Scrum Master |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4 (via Cursor)

### Debug Log References
- All tests passing: 21/21 tests successful
- ConfigService: 7/7 tests passed
- ChatService: 7/7 tests passed  
- Chat API: 7/7 tests passed

### Completion Notes List
- ✅ Environment configuration service created with proper validation
- ✅ OpenAI API integration service implemented with error handling
- ✅ Chat API route created with Zod validation and proper error responses
- ✅ TypeScript interfaces defined for all chat-related data models
- ✅ Comprehensive unit tests written and all passing
- ✅ Proper error handling for OpenAI API errors and validation errors
- ✅ Health check endpoint implemented for API monitoring

### File List
**New Files Created:**
- `src/services/configService.ts` - Environment configuration management
- `src/services/chatService.ts` - OpenAI API integration service
- `src/app/api/chat/route.ts` - Chat API endpoint with POST and GET handlers
- `tests/services/configService.test.ts` - ConfigService unit tests
- `tests/services/chatService.test.ts` - ChatService unit tests
- `tests/api/chat.test.ts` - Chat API endpoint tests

**Modified Files:**
- `src/types/index.ts` - Added chat-related TypeScript interfaces (ChatRequest, ChatResponse, ChatMessage, OpenAIConfig, ErrorResponse)

## QA Results
*To be populated by QA Agent*
