# Story 3.2: Context Flattening and Path Traversal

## Status
Draft

## Story

**As a** developer,
**I want** to implement path traversal and context flattening,
**so that** the LLM receives proper conversation context from active nodes.

## Acceptance Criteria

1. Active node path is correctly calculated from clicked node to source
2. Path is flattened into user/assistant message pairs
3. Context includes proper message formatting for OpenAI API
4. Context length is managed to stay within API limits
5. Context preservation maintains conversation flow and meaning
6. Path calculation handles edge cases and complex branching
7. Context flattening is efficient and doesn't impact performance

## Tasks / Subtasks

- [ ] Task 1: Implement Path Traversal Algorithm (AC: 1, 6)
  - [ ] Create graphTraversal utility for path calculation
  - [ ] Implement recursive path finding from node to root
  - [ ] Handle complex branching scenarios and multiple paths
  - [ ] Add validation for circular references and orphaned nodes
  - [ ] Create unit tests for path calculation edge cases

- [ ] Task 2: Create Context Flattening Service (AC: 2, 3)
  - [ ] Create ContextService for flattening conversation paths
  - [ ] Implement user/assistant message pair extraction
  - [ ] Format messages according to OpenAI API requirements
  - [ ] Add message ordering and sequence validation
  - [ ] Handle empty or invalid context scenarios

- [ ] Task 3: Implement Context Length Management (AC: 4, 5)
  - [ ] Add token counting for context messages
  - [ ] Implement context truncation strategies
  - [ ] Preserve conversation flow when truncating
  - [ ] Add configurable context length limits
  - [ ] Optimize context selection for relevance

- [ ] Task 4: Create Context Data Models (AC: 3)
  - [ ] Define ContextMessage interface for flattened messages
  - [ ] Create ConversationPath interface for path data
  - [ ] Add ContextConfig interface for configuration
  - [ ] Implement validation schemas for context data
  - [ ] Add utility types for context operations

- [ ] Task 5: Integrate with Chat API (AC: 1-7)
  - [ ] Update ChatService to use context flattening
  - [ ] Integrate path traversal with node activation
  - [ ] Add context validation before API calls
  - [ ] Implement context caching for performance
  - [ ] Add context debugging and logging

- [ ] Task 6: Create Unit Tests (AC: 1-7)
  - [ ] Test path traversal with various graph structures
  - [ ] Test context flattening with different message types
  - [ ] Test context length management and truncation
  - [ ] Test edge cases and error handling
  - [ ] Test performance with large conversation graphs

## Dev Notes

### Previous Story Insights
**Story 3.1 Context** [Source: stories/3.1.story.md]
- OpenAI API integration is implemented
- Chat API route exists at `/api/chat`
- Basic request/response data models are defined
- Error handling and monitoring are in place

**Epic 2 Context** [Source: stories/2.1-2.5.story.md]
- Node activation and path calculation functionality exists
- Graph state management with activeNodePath is implemented
- ConversationNode components handle different states
- React Flow integration provides graph structure

### Data Models
**ContextMessage Interface** [Source: architecture/data-models.md#conversation]
```typescript
interface ContextMessage {
  role: 'user' | 'assistant';
  content: string;
  nodeId: string;
  timestamp: Date;
  metadata?: {
    isTruncated?: boolean;
    originalLength?: number;
  };
}
```

**ConversationPath Interface** [Source: architecture/data-models.md#node]
```typescript
interface ConversationPath {
  nodeIds: string[];
  messages: ContextMessage[];
  totalTokens: number;
  isComplete: boolean;
  lastTruncatedAt?: string;
}
```

**ContextConfig Interface** [Source: architecture/backend-architecture.md#service-architecture]
```typescript
interface ContextConfig {
  maxTokens: number;
  maxMessages: number;
  preserveOrder: boolean;
  includeMetadata: boolean;
  truncationStrategy: 'head' | 'tail' | 'smart';
}
```

### Component Specifications
**GraphTraversal Utility** [Source: architecture/frontend-architecture.md#component-organization]
- Location: `src/utils/graphTraversal.ts`
- Functions: `calculatePathToRoot`, `findNodeById`, `validatePath`
- Handles complex branching scenarios
- Prevents circular references and infinite loops

**ContextService** [Source: architecture/backend-architecture.md#service-architecture]
- Location: `src/services/contextService.ts`
- Functions: `flattenConversationPath`, `calculateContextTokens`, `truncateContext`
- Manages context length and formatting
- Integrates with OpenAI API requirements

**ChatService Integration** [Source: architecture/backend-architecture.md#service-architecture]
- Location: `src/services/chatService.ts`
- Uses ContextService for path flattening
- Validates context before API calls
- Handles context-related errors

### File Locations
**Utility Files** [Source: architecture/unified-project-structure.md]
- Graph traversal: `src/utils/graphTraversal.ts`
- Context utilities: `src/utils/contextUtils.ts`
- Token counting: `src/utils/tokenCounter.ts`

**Service Files** [Source: architecture/backend-architecture.md#service-architecture]
- Context service: `src/services/contextService.ts`
- Chat service: `src/services/chatService.ts`
- Configuration: `src/services/configService.ts`

**Type Definitions** [Source: architecture/coding-standards.md#type-sharing]
- Context types: `src/types/context.ts`
- Graph types: `src/types/graph.ts`
- Shared types: `src/types/index.ts`

### Path Traversal Algorithm
**Path Calculation Logic** [Source: architecture/frontend-architecture.md#state-management-patterns]
- Start from clicked node and traverse to root
- Follow parentNodeId references in reverse
- Handle multiple parent scenarios (branching)
- Validate path integrity and prevent cycles
- Return ordered array of node IDs

**Edge Case Handling** [Source: architecture/frontend-architecture.md#state-management-patterns]
- Orphaned nodes (no parent reference)
- Circular references in graph structure
- Invalid node references
- Empty or malformed conversation data
- Performance optimization for large graphs

### Context Flattening Process
**Message Extraction** [Source: architecture/data-models.md#node]
- Extract userMessage and assistantResponse from each node
- Create user/assistant message pairs
- Preserve chronological order of messages
- Include node metadata for context

**OpenAI API Formatting** [Source: architecture/external-apis.md#openai-api]
- Format messages according to OpenAI chat completions API
- Include proper role assignments (user/assistant)
- Handle markdown content in messages
- Add system messages for context

### Context Length Management
**Token Counting** [Source: architecture/external-apis.md#openai-api]
- Count tokens for each message in context
- Calculate total context token usage
- Implement efficient token counting algorithm
- Handle different tokenization for different models

**Truncation Strategies** [Source: architecture/backend-architecture.md#service-architecture]
- Head truncation: Remove oldest messages
- Tail truncation: Remove newest messages
- Smart truncation: Preserve important context
- Configurable truncation thresholds

### Performance Optimization
**Context Caching** [Source: architecture/security-and-performance.md#performance-optimization]
- Cache calculated paths for frequently accessed nodes
- Implement cache invalidation on graph changes
- Optimize context calculation for large graphs
- Memory-efficient context storage

**Efficient Algorithms** [Source: architecture/security-and-performance.md#performance-optimization]
- O(n) path traversal algorithm
- Efficient token counting without full re-parsing
- Lazy loading of context data
- Optimized data structures for graph operations

### Testing Requirements
**Test File Locations** [Source: architecture/testing-strategy.md#backend-tests]
- Graph traversal tests: `tests/utils/graphTraversal.test.ts`
- Context service tests: `tests/services/contextService.test.ts`
- Integration tests: `tests/integration/context.test.ts`

**Test Standards** [Source: architecture/testing-strategy.md#backend-api-test]
- Test path calculation with various graph structures
- Test context flattening with different message types
- Test context length management and truncation
- Test edge cases and error handling
- Test performance with large conversation graphs

### Technical Constraints
**OpenAI API Limits** [Source: architecture/external-apis.md#openai-api]
- Maximum context length per model
- Token limits for input and output
- Request size limitations
- Rate limiting considerations

**Graph Complexity** [Source: architecture/frontend-architecture.md#state-management-patterns]
- Handle graphs with hundreds of nodes
- Efficient traversal for deep conversation trees
- Memory usage optimization
- Performance degradation prevention

**Context Quality** [Source: architecture/backend-architecture.md#service-architecture]
- Maintain conversation coherence
- Preserve important context information
- Handle context truncation gracefully
- Ensure meaningful LLM responses

### Error Handling
**Path Traversal Errors** [Source: architecture/error-handling-strategy.md#backend-error-handling]
- Invalid node references
- Circular dependency detection
- Orphaned node handling
- Graph corruption recovery

**Context Flattening Errors** [Source: architecture/error-handling-strategy.md#backend-error-handling]
- Empty or invalid conversation data
- Message formatting errors
- Token counting failures
- Context validation errors

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-12-19 | 1.0 | Initial story creation | Scrum Master |

## Dev Agent Record

### Agent Model Used
*To be populated by Dev Agent*

### Debug Log References
*To be populated by Dev Agent*

### Completion Notes List
*To be populated by Dev Agent*

### File List
*To be populated by Dev Agent*

## QA Results
*To be populated by QA Agent*
